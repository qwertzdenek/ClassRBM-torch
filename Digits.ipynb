{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load dataset\n",
    "------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mnist = require('mnist')\n",
    "\n",
    "torch.seed()\n",
    "\n",
    "testset = mnist.testdataset()\n",
    "testset['data'] = testset['data']:double():clamp(0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "inputs_x = torch.Tensor(100, 28*28)\n",
    "inputs_y = torch.ByteTensor(100)\n",
    "for i=1, 100 do\n",
    "    num = torch.random(testset.size)\n",
    "    inputs_x[i]:copy(testset[num].x)\n",
    "    inputs_y[i] = testset[num].y\n",
    "end\n",
    "\n",
    "wm = image.toDisplayTensor{\n",
    "    input=inputs_x:view(torch.LongStorage{100, 28, 28}),\n",
    "    padding=2, nrow=10}\n",
    "itorch.image(wm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classify\n",
    "--------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will forward classification RBM with zero class vector and do one step Gibbs sampling from the input digit. Resulting digit class is stored to the *class_y*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "require('classrbm')\n",
    "\n",
    "rbm = torch.load('models/trained_rbm_final.dat')\n",
    "\n",
    "classrbm = ClassRBM(rbm.n_visible, rbm.n_hidden, rbm.n_class, rbm.batch)\n",
    "classrbm.weight = rbm.weight\n",
    "classrbm.vbias = rbm.vbias\n",
    "classrbm.hbias = rbm.hbias\n",
    "classrbm.uweight = rbm.uweight\n",
    "classrbm.dbias = rbm.dbias\n",
    "\n",
    "class_y = torch.ByteTensor(100)\n",
    "\n",
    "for i=1, 100 do\n",
    "    vt, yt = classrbm:forward{inputs_x[i], torch.zeros(10)}\n",
    "    _, y = torch.max(yt,1)\n",
    "    y = y-1 -- because index from 1\n",
    "    \n",
    "    class_y[i] = y\n",
    "end\n",
    "\n",
    "print(class_y:view(10,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification error\n",
    "--------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "oneY = torch.Tensor(10)\n",
    "validation_size = 256\n",
    "\n",
    "err = 0\n",
    "\n",
    "for i=1, validation_size do\n",
    "    local index = torch.random(testset.size)\n",
    "    local v1 = testset[index].x:view(28*28)\n",
    "    local y1 = testset[index].y\n",
    "    oneY:zero()\n",
    "    oneY[y1+1] = 1\n",
    "    local v2, y2 = classrbm:forward{v1, oneY}\n",
    "    err = err + (torch.ne(oneY, y2):sum() == 0 and 0 or 1)\n",
    "end\n",
    "\n",
    "print(100*(1-err/validation_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weights\n",
    "------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wm = image.toDisplayTensor{\n",
    "    input=classrbm.weight:view(torch.LongStorage{classrbm.n_hidden, 28, 28}),\n",
    "    padding=2, nrow=22}\n",
    "itorch.image(wm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample new digits\n",
    "-----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is posible with this architecture http://www.cs.toronto.edu/~hinton/adi."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iTorch",
   "language": "lua",
   "name": "itorch"
  },
  "language_info": {
   "name": "lua",
   "version": "5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
